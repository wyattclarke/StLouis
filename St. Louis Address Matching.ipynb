{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# St. Louis Address Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for setting up:\n",
    "\n",
    "1. **Clone or download** this Github repository: [insert link]\n",
    "2. **Download Conda.** The part of the code that uses ArcPy only works using the Conda distribution that comes with an ArcGIS Pro download (free for UCI affiliates, contact tsoeller@uci.edu). Everything else should work with any installation of Python 3: https://www.continuum.io/downloads.\n",
    "3. **Download Python packages** that are not included with Anaconda, using the command-line as an administrator:\n",
    "```\n",
    "pip install lob\n",
    "pip install pygeocoder\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages** and set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing required dependencies ['numpy']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-97ad7f83671c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Missing required dependencies {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mhard_dependencies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdependency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing required dependencies ['numpy']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import lob\n",
    "import os\n",
    "import sys\n",
    "from pygeocoder import Geocoder\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "import numpy as np\n",
    "\n",
    "os.chdir(r'C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next 3 cells standardize lists of addresses using Lob's free API, so that the lists can be merged. The API checks against USPS's current list of valid postal addresses and returns the address in CASS format: https://en.wikipedia.org/wiki/Coding_Accuracy_Support_System.\n",
    "\n",
    "The API returns about 2 addresses per second, so it can take a while. The output is stored in a *.csv, meaning you can skip this step. If you want to make sure it works without re-running the whole cell, run a few addresses and save to a different file. Do this in the first cell by replacing the first line with:\n",
    "```\n",
    "approved = pd.read_csv('Approved_StLouis_Cleaned.csv').head()\n",
    "``` \n",
    "and the last line with:\n",
    "```\n",
    "approved.to_csv('delete.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) **Addresses of approved applicants** (Takes a long time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approved = pd.read_csv('Approved_StLouis_Cleaned.csv') # Import .csv\n",
    "\n",
    "lob.api_key = 'test_fc26575412e92e22a926bc96c857f375f8b'\n",
    "\n",
    "for index, row in approved.iterrows():\n",
    "    try:    \n",
    "        verifiedAddress = lob.Verification.create(\n",
    "            address_line1=row['street'],\n",
    "            address_city=row['city'],\n",
    "            address_state=row['state'],\n",
    "            address_zip=row['zip'],\n",
    "            address_country='US'\n",
    "        )\n",
    "        approved.ix[approved.index == index, 'lob_addr1'] = verifiedAddress.address.address_line1\n",
    "        approved.ix[approved.index == index, 'lob_addr2'] = verifiedAddress.address.address_line2\n",
    "        approved.ix[approved.index == index, 'lob_city'] = verifiedAddress.address.address_city\n",
    "        approved.ix[approved.index == index, 'lob_zip'] = verifiedAddress.address.address_zip               \n",
    "    except:\n",
    "        approved.ix[approved.index == index, 'lob_addr1'] = \"no\"\n",
    "        approved.ix[approved.index == index, 'lob_addr2'] = \"no\"\n",
    "        approved.ix[approved.index == index, 'lob_city'] = \"no\"\n",
    "        approved.ix[approved.index == index, 'lob_zip'] = \"no\"       \n",
    "                   \n",
    "approved.to_csv('lob_approved.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) **Addresses of denied applicants**  (Takes a long time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denied = pd.read_csv('Denied_StLouis_Cleaned.csv')\n",
    "\n",
    "lob.api_key = 'test_fc26575412e92e22a926bc96c857f375f8b'\n",
    "\n",
    "for index, row in denied.iterrows():\n",
    "    try:    \n",
    "        verifiedAddress = lob.Verification.create(\n",
    "            address_line1=row['street'],\n",
    "            address_city=row['city'],\n",
    "            address_state=row['state'],\n",
    "            address_zip=row['zip'],\n",
    "            address_country='US'\n",
    "        )\n",
    "        denied.ix[denied.index == index, 'lob_addr1'] = verifiedAddress.address.address_line1\n",
    "        denied.ix[denied.index == index, 'lob_addr2'] = verifiedAddress.address.address_line2\n",
    "        denied.ix[denied.index == index, 'lob_city'] = verifiedAddress.address.address_city\n",
    "        denied.ix[denied.index == index, 'lob_zip'] = verifiedAddress.address.address_zip               \n",
    "    except:\n",
    "        denied.ix[denied.index == index, 'lob_addr1'] = \"no\"\n",
    "        denied.ix[denied.index == index, 'lob_addr2'] = \"no\"\n",
    "        denied.ix[denied.index == index, 'lob_city'] = \"no\"\n",
    "        denied.ix[denied.index == index, 'lob_zip'] = \"no\"       \n",
    "                   \n",
    "denied.to_csv('lob_denied.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) **County assessor's list of land parcels associated to postal addresses.** Each land parcel may have multiple postal addresses but has a unique \"handle\".  (Takes a long time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Address to Parcel Mapping by St Louis city govt\n",
    "a2p = pd.read_csv('addr_to_parcel.csv')\n",
    "\n",
    "a2p['street'] = a2p['HOUSENUM'].fillna('').astype(str) + \" \" + a2p['HOUSESUF'].fillna('').astype(str)\n",
    "a2p['street'] = a2p['street'].str.rstrip(\" \")\n",
    "\n",
    "a2p['street'] = a2p['street'].fillna('').astype(str) + \" \" + a2p['PREDIR'].fillna('').astype(str)\n",
    "a2p['street'] = a2p['street'].str.rstrip(\" \")\n",
    "\n",
    "a2p['street'] = a2p['street'].fillna('').astype(str) + \" \" + a2p['STREETNAME'].fillna('').astype(str)\n",
    "a2p['street'] = a2p['street'].str.rstrip(\" \")\n",
    "\n",
    "a2p['street'] = a2p['street'].fillna('').astype(str) + \" \" + a2p['STREETTYPE'].fillna('').astype(str)\n",
    "a2p['street'] = a2p['street'].str.rstrip(\" \")\n",
    "\n",
    "a2p['street'] = a2p['street'].fillna('').astype(str) + \" \" + a2p['SUFDIR'].fillna('').astype(str)\n",
    "a2p['street'] = a2p['street'].str.rstrip(\" \")\n",
    "\n",
    "a2p['street'] = a2p['street'].fillna('').astype(str) + \" \" + a2p['UNITNUM'].fillna('').astype(str)\n",
    "a2p['street'] = a2p['street'].str.rstrip(\" \")\n",
    "\n",
    "for index, row in a2p.iterrows():\n",
    "    try:    \n",
    "        verifiedAddress = lob.Verification.create(\n",
    "            address_line1=row['street'],\n",
    "            address_city=\"Saint Louis\",\n",
    "            address_state=\"MO\",\n",
    "            address_country='US'\n",
    "        )\n",
    "        a2p.ix[a2p.index == index, 'lob_addr1'] = verifiedAddress.address.address_line1\n",
    "        a2p.ix[a2p.index == index, 'lob_addr2'] = verifiedAddress.address.address_line2\n",
    "        a2p.ix[a2p.index == index, 'lob_city'] = verifiedAddress.address.address_city\n",
    "        a2p.ix[a2p.index == index, 'lob_zip'] = verifiedAddress.address.address_zip               \n",
    "    except:\n",
    "        a2p.ix[a2p.index == index, 'lob_addr1'] = \"no\"\n",
    "        a2p.ix[a2p.index == index, 'lob_addr2'] = \"no\"\n",
    "        a2p.ix[a2p.index == index, 'lob_city'] = \"no\"\n",
    "        a2p.ix[a2p.index == index, 'lob_zip'] = \"no\"       \n",
    "\n",
    "                   \n",
    "a2p.to_csv('lob_a2p.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge applicant addresses to city parcels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that addresses are in a standard format, <strong>merge applicant addresses</strong> (both approved and denied) to a unique parcel \"handle\" using the St Louis city address list. \n",
    "\n",
    "We first make some adjustments to maximize the number of addresses that will merge successfully: \n",
    "1. Remove apartment numbers from applicant addresses since parcels never have an apartment number.\n",
    "2. The API doesn't return a result for some applicant addresses, meaning they weren't recognized as valid postal addresses. Reasons include (1) the address is incomplete or written incorrectly, (2) the house is vacant, so not an address where USPS delivers, or (3) the application is for an address that doesn't exist yet, in anticipation of a parcel split. For this reason, create a combined column with the standardized address if there is one and the original address if the API returned no result.\n",
    "\n",
    "This cell generates a lot of warnings, but it runs. Addresses that fail to merge in this cell are dealt with later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approved = pd.read_csv('lob_approved.csv')\n",
    "# Remove apartment numbers\n",
    "approved['lob_addr1'] = approved['lob_addr1'].apply(lambda x: x.split(' #')[0])\n",
    "approved['street'] = approved['street'].apply(lambda x: x.split(' #')[0])\n",
    "\n",
    "denied = pd.read_csv('lob_denied.csv')\n",
    "# Remove apartment numbers\n",
    "denied['lob_addr1'] = denied['lob_addr1'].apply(lambda x: x.split(' #')[0])\n",
    "denied['street'] = denied['street'].apply(lambda x: x.split(' #')[0])\n",
    "\n",
    "a2p = pd.read_csv('lob_a2p.csv') # a2p means \"address to parcel\"\n",
    "\n",
    "# Create combined address column\n",
    "approved['best_addr1'] = approved['lob_addr1']\n",
    "mask = approved['best_addr1']=='no'\n",
    "approved['best_addr1'][mask] = approved['street'].str.upper()\n",
    "approved['best_addr1'] = approved['best_addr1'].str.replace('.','')\n",
    "approved['best_city'] = approved['lob_city']\n",
    "approved['best_city'][mask] = approved['city'].str.upper()\n",
    "approved['best_zip'] = approved['lob_zip']\n",
    "approved['best_zip'][mask] = approved['zip']\n",
    "\n",
    "# Create combined address column\n",
    "denied['best_addr1'] = denied['lob_addr1']\n",
    "mask = denied['best_addr1']=='no'\n",
    "denied['best_addr1'][mask] = denied['street'].str.upper()\n",
    "denied['best_addr1'] = denied['best_addr1'].str.replace('.','')\n",
    "denied['best_addr1'] = denied['best_addr1'].str.replace('STREET','ST')\n",
    "denied['best_addr1'] = denied['best_addr1'].str.replace('AVENUE','AVE')\n",
    "denied['best_city'] = denied['lob_city']\n",
    "denied['best_city'][mask] = denied['city'].str.upper()\n",
    "denied['best_zip'] = denied['lob_zip']\n",
    "denied['best_zip'][mask] = denied['zip']\n",
    "\n",
    "# Create combined address column\n",
    "a2p['best_addr1'] = a2p['lob_addr1']\n",
    "mask = a2p['best_addr1']=='no'\n",
    "a2p['best_addr1'][mask] = a2p['street'].str.upper()\n",
    "a2p['best_city'] = a2p['lob_city']\n",
    "a2p['best_city'][mask] = 'SAINT LOUIS'\n",
    "a2p['best_zip'] = a2p['lob_zip']\n",
    "a2p['best_zip'][mask] = ''\n",
    "a2p_lob = a2p[['HANDLE', 'best_addr1', 'best_city']]\n",
    "a2p_lob = a2p_lob.drop_duplicates(['best_addr1', 'best_city'])\n",
    "\n",
    "# Perform the actual merges\n",
    "approved = approved.merge(a2p_lob,left_on=['best_addr1', 'best_city'], right_on=['best_addr1', 'best_city'], how='left')\n",
    "denied = denied.merge(a2p_lob,left_on=['best_addr1', 'best_city'], right_on=['best_addr1', 'best_city'], how='left')\n",
    "\n",
    "# Save to .csv\n",
    "approved.to_csv('approved_matched.csv')\n",
    "denied.to_csv('denied_matched.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a combined **list of all the addresses that failed to merge** with a parcel located in St Louis city limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unmatched_approved = approved[approved['HANDLE'].isnull()][['lob_addr1', 'lob_city', 'lob_zip', 'HANDLE', 'best_addr1', 'best_city', 'best_zip']]\n",
    "unmatched_approved['source'] = \"approved\"\n",
    "unmatched_denied = denied[denied['HANDLE'].isnull()][['lob_addr1', 'lob_city', 'lob_zip', 'HANDLE', 'best_addr1', 'best_city', 'best_zip']]\n",
    "unmatched_denied['source'] = \"denied\"\n",
    "\n",
    "unmatched = unmatched_approved.append(unmatched_denied)\n",
    "unmatched['best_address'] = unmatched['best_addr1'].astype(str) + \", \" + unmatched['best_city'].astype(str) + \", MO \" + unmatched['best_zip'].astype(str)\n",
    "unmatched_address = unmatched[['best_address']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fix** a few specific **typos** and quirks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unmatched_address['best_address'] = unmatched_address['best_address'].str.replace('GLENECHORT','GLENCHORT')\n",
    "unmatched_address['best_address'] = unmatched_address['best_address'].str.replace('PARKER GRAY','PARKERGREY')\n",
    "unmatched_address['best_address'] = unmatched_address['best_address'].str.replace('1720 SOUTH 14TH ST','1720 S 14TH ST')\n",
    "unmatched_address['best_address'] = unmatched_address['best_address'].apply(lambda x: x.split(' REAR')[0])\n",
    "unmatched_address['best_address'] = unmatched_address['best_address'].apply(lambda x: x.split(' FRNT')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geocode** addresses of unmatched addresses, using Google's Geocoding API. (This takes a long time.)\n",
    "\n",
    "The first 2,500 addresses geocoded in a given day are free. Any more are billed at $1 per 1,000 geocodes. This step geocodes 1,841 addresses. Thus, you'll need to insert an API key to run this more than once in a day. That is replace the 3rd line with:\n",
    "```\n",
    "results = Geocoder('<<YOUR KEY>>').geocode(address)\n",
    "```\n",
    "\n",
    "You can sign up for a Google Geocoding API key at https://developers.google.com/maps/documentation/geocoding/start. [Matt, I'll email you mine. I just don't want it up on Github.]\n",
    "\n",
    "[Matt, FYI, we might technically be violating Google Geocoding API's terms of service, which say \"The Google Maps Geocoding API may only be used in conjunction with displaying results on a Google map. It is prohibited to use Google Maps Geocoding API data without displaying a Google map.\" We can use another geocoding API if it ever becomes a problem.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Google_geocode(address):\n",
    "    try:\n",
    "        results = Geocoder.geocode(address)  # API key with payment method required for +2500 queries per day\n",
    "        return results.coordinates\n",
    "        print(index)\n",
    "    except:\n",
    "        return (0.0, 0.0)\n",
    "unmatched_address['best_lat'], unmatched_address['best_lon'] = zip(*unmatched_address['best_address'].apply(Google_geocode))\n",
    "unmatched_address.to_csv('unmatched_address.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only an upduplicated list of unmatched addresses is geocoded, to keep the process \"cheap\". After geocoding, rematch to the full list of unmatched applications, which contains some duplicate addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unmatched_address = pd.read_csv('unmatched_address.csv')\n",
    "unmatched = unmatched.merge(unmatched_address,left_on='best_address', right_on='best_address', how='left')\n",
    "unmatched.to_csv('unmatched.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlay geocodes of unmatched addresses and the assessor's parcel map in ArcGIS. Use these to perform matches, described later. \n",
    "\n",
    "Running this cell requires the ArcPy package, which comes in the Conda installation included with ArcGIS Pro. You have to be signed in to ArcGIS Pro via the web to run ArcPy. You would also have to change the filepaths to run this cell. [Open source software could do this. I just happen to work in ArcGIS. We can change this part later if needed.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Set ArcPy environment settings\n",
    "arcpy.env.workspace = r'C:\\Users\\wyatt.clarke\\Documents\\ArcGIS\\Projects\\StLouis\\StLouis.gdb'\n",
    "arcpy.env.overwriteOutput = True\n",
    "    # Add points to ArcGIS as a Table and display them on the map\n",
    "        #TableToTable_conversion (in_rows, out_path, out_name, {where_clause}, {field_mapping}, {config_keyword})\n",
    "arcpy.TableToTable_conversion(r'C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\unmatched.csv', r'C:\\Users\\wyatt.clarke\\Documents\\ArcGIS\\Projects\\StLouis\\StLouis.gdb', \"unmatched6\")\n",
    "        #MakeXYEventLayer_management(in_Table, x_coords, y_coords, out_Layer, spRef, z_coords)\n",
    "arcpy.management.MakeXYEventLayer(\"unmatched6\", \"best_lon\", \"best_lat\", \"unmatched\", \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\", None)\n",
    "    # Add St Louis city limits\n",
    "        #CopyFeatures_management (in_features, out_feature_class, {config_keyword}, {spatial_grid_1}, {spatial_grid_2}, {spatial_grid_3})\n",
    "arcpy.management.CopyFeatures(r'C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\shapefiles\\stl_boundary.shp', 'stl_boundary', None, None, None, None)\n",
    "arcpy.management.CopyFeatures(r'C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\shapefiles\\prcl.shp', 'prcl', None, None, None, None)\n",
    "    # Find which points fall inside the city using a spatial join\n",
    "        #SpatialJoin_analysis (target_features, join_features, out_feature_class, {join_operation}, {join_type}, {field_mapping}, {match_option}, {search_radius}, {distance_field_name})\n",
    "arcpy.analysis.SpatialJoin(\"unmatched\", \"stl_boundary\", r\"C:\\Users\\wyatt.clarke\\Documents\\ArcGIS\\Projects\\StLouis\\StLouis.gdb\\unmatched_SpatialJoin\", \"JOIN_ONE_TO_MANY\", \"KEEP_ALL\", 'lob_addr1 \"lob_addr1\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,lob_addr1,0,8000;lob_city \"lob_city\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,lob_city,0,8000;lob_zip \"lob_zip\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,lob_zip,0,8000;HANDLE \"HANDLE\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,HANDLE,0,8000;best_addr1 \"best_addr1\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,best_addr1,0,8000;best_city \"best_city\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,best_city,0,8000;best_zip \"best_zip\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,best_zip,0,8000;source \"source\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,source,0,8000;best_address \"best_address\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,best_address,0,8000;best_lat \"best_lat\" true true false 8 Double 0 0,First,#,unmatched3_Layer,best_lat,-1,-1;best_lon \"best_lon\" true true false 8 Double 0 0,First,#,unmatched3_Layer,best_lon,-1,-1;LAYER \"LAYER\" true true false 32 Text 0 0,First,#,stl_boundary,LAYER,0,32', \"INTERSECT\", None, None)\n",
    "arcpy.analysis.SpatialJoin(\"unmatched_SpatialJoin\", \"prcl\", r\"C:\\Users\\wyatt.clarke\\Documents\\ArcGIS\\Projects\\StLouis\\StLouis.gdb\\unmatched_SpatialJoin1\", \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", 'lob_addr1 \"lob_addr1\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,lob_addr1,0,8000;lob_city \"lob_city\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,lob_city,0,8000;lob_zip \"lob_zip\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,lob_zip,0,8000;HANDLE \"HANDLE\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,HANDLE,0,8000;best_addr1 \"best_addr1\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,best_addr1,0,8000;best_city \"best_city\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,best_city,0,8000;best_zip \"best_zip\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,best_zip,0,8000;source \"source\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,source,0,8000;best_address \"best_address\" true true false 8000 Text 0 0,First,#,unmatched3_Layer,best_address,0,8000;best_lat \"best_lat\" true true false 8 Double 0 0,First,#,unmatched3_Layer,best_lat,-1,-1;best_lon \"best_lon\" true true false 8 Double 0 0,First,#,unmatched3_Layer,best_lon,-1,-1;LAYER \"LAYER\" true true false 32 Text 0 0,First,#,stl_boundary,LAYER,0,32;HANDLE_1 \"HANDLE\" true true false 16 Text 0 0,First,#,prcl,HANDLE,0,16', \"INTERSECT\", None, None)\n",
    "\n",
    "arcpy.stats.ExportXYv(\"unmatched_SpatialJoin1\", \"lob_addr1;lob_city;lob_zip;HANDLE;HANDLE_1;best_addr1;best_city;best_zip;source;best_address;best_lat;best_lon;LAYER\", \"SEMI-COLON\", r\"C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\unmatched_vCityLimits_ArcExport.csv\", \"ADD_FIELD_NAMES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous cell made an overlay of applicant addresses and parcels. Use this overlay to resolve unmatched addresses as follows: \n",
    "1. Geocoded applicant addresses that overlap a parcel are assigned to that parcel. \n",
    "2. Geocoded applications that are outside of St. Louis city limits are thrown out. \n",
    "3. Records that weren't geocoded are set to a missing handle value and dealt with later.\n",
    "3. Geocodes are either to the roof top or to the street center line. Geocodes to the street center line don't overlap any parcel. The resolution of these cases is explained below. \n",
    "\n",
    "Create a variable to start keeping track of how matches are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unmatched = pd.read_csv('unmatched_vCityLimits_ArcExport.csv',sep=';')\n",
    "unmatched['match_type'] = np.nan\n",
    "\n",
    "# Apply the handle assigned by ArcGIS, subject to 3 caveats in the lines that follow\n",
    "unmatched['HANDLE'] = unmatched['HANDLE_1']\n",
    "unmatched['match_type'][unmatched['HANDLE_1'].notnull()] = 'GIS_overlay_insideSTL'\n",
    "\n",
    "mask = unmatched['LAYER'].isnull() # Set records not found to be in St. Louis city limits to handle value 9999 (un-geocoded are modified by the next condition)\n",
    "unmatched['HANDLE'][mask] = 9999 \n",
    "unmatched['match_type'][mask] = 'GIS_overlay_outsideSTL'\n",
    "\n",
    "mask = unmatched['XCoord']==0 # Set records that weren't geocoded to a missing handle value\n",
    "unmatched['HANDLE'][mask] = np.nan \n",
    "unmatched['match_type'][mask] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first place things get messy. \n",
    "\n",
    "About 70 applications list multiple street addresses (e.g., \"4560 & 4562 Oak Ln\"). I manually matched the relevant parcels to these applications in a spreadsheet, based on visual inspection of ArcGIS. The maximum number of parcels for one application is 4, listed in 4 separate columns. This cell adds these matches to the larger list.\n",
    "\n",
    "Continue keeping track of how matches are made using the <i>match_type</i> column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi = pd.read_csv('multi.csv', index_col=\"INDEX\")\n",
    "unmatched = unmatched.merge(multi, left_index=True, right_index=True, how='left')\n",
    "\n",
    "mask = unmatched['HANDLE_M1'].notnull()\n",
    "unmatched['match_type'][mask] = 'manual_multi'\n",
    "\n",
    "unmatched['HANDLE_M1'][~mask] = unmatched['HANDLE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 400 applications are geocoded to the street center line and don't overlap any parcel. Instead, these addresses are assigned to (up to) two nearby parcels on the same block face: the parcel with the next highest house number and the parcel with the next lowest house number. The working assumption is that the applicant was thinking of building on one of these two parcels.\n",
    "\n",
    "Finding houses above and below on the same block face required separating street name from house number. This was done by hand in Excel.\n",
    "\n",
    "Several address typos are corrected before doing this match. If the \"fixed\" application address now matches a parcel address exactly, only that one parcel is assigned.\n",
    "\n",
    "(Takes ~2 minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For addresses with no matching parcel address that are geocoded to the street centerline, match to the parcels above and below it on the same size of the street and on the same block\n",
    "    # Create csv in Excel by hand to isolate street name\n",
    "between = pd.read_csv('between.csv') \n",
    "    # Fix some problems in the addresses\n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('CRANE', 'CRANE CIRCLE')\n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('FARIMONT', 'FAIRMOUNT')\n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('HERBERT', 'HEBERT')\n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('KENSINGSTON', 'KENSINGTON')\n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('LOVELOY', 'LOVEJOY')\n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('MALLINCRODT', 'MALLINCKRODT')\n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('MARYLAND,', 'MARYLAND')\n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('MONGTGOMERY', 'MONTGOMERY')\n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('PRAIRE', 'PRAIRIE')  \n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('REV G H PRUITT', 'REV GEORGE H PRUITT')                     \n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('SAINT FERDINAND', 'ST FERDINAND')                     \n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('SAINT LOUIS', 'ST LOUIS')                     \n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('SAINT VINCENT', 'VINCENT')                     \n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('VINCENT', 'ST VINCENT')  \n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('WINSOR', 'WINDSOR')                     \n",
    "between['STREET_NAME'] = between['STREET_NAME'].str.replace('WASHINGON', 'WASHINGTON')                      \n",
    "    # Merge isolated street name into the larger list of unmatched addresses\n",
    "unmatched['INDEX'] = unmatched.index\n",
    "unmatched = unmatched.merge(between, left_on='INDEX', right_on='INDEX', how='left')\n",
    "    # Create variables to designate side of street and block number\n",
    "a2p['EVEN'] = 0\n",
    "a2p['EVEN'][a2p['HOUSENUM'].astype(int) % 2 == 0] = 1\n",
    "a2p['EVEN'] = a2p['EVEN'].astype(float)\n",
    "a2p['BLOCK'] = a2p['HOUSENUM'].astype(float).floordiv(100)\n",
    "a2p['STREETNAME'] = a2p['PREDIR'].fillna('').astype(str) + \" \" + a2p['STREETNAME']\n",
    "a2p['STREETNAME'] = a2p['STREETNAME'].str.lstrip(\" \")\n",
    "a2p = a2p[a2p['HANDLE']!=12022000010] # 1,200 addresses are all assigned to the center of a city park (ie, parcel 12022000010), so I'm throwing it out.\n",
    "unmatched['BLOCK'] = unmatched['HOUSE'].floordiv(100)\n",
    "unmatched['HIGH'] = np.nan\n",
    "unmatched['LOW'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For loops to find address immediately below and above and the corresponding parcel. (Keep separate so that 1 can succeed even if the other finds nothing.)\n",
    "for index, row in unmatched.iterrows():\n",
    "    try:\n",
    "        samestreet = a2p.STREETNAME==row['STREET_NAME']\n",
    "        sameblock = a2p.BLOCK==row['BLOCK']\n",
    "        evenOdd = a2p.EVEN==row['EVEN']\n",
    "        lower = a2p.HOUSENUM<=row['HOUSE']\n",
    "        a2p_lower = a2p[samestreet][sameblock][evenOdd][lower][::-1].reset_index() \n",
    "        unmatched.ix[unmatched.index == index, 'house_LOW'] = a2p_lower.ix[0,'HOUSENUM']\n",
    "        unmatched.ix[unmatched.index == index, 'street_LOW'] = a2p_lower.ix[0,'STREETNAME']\n",
    "        unmatched.ix[unmatched.index == index, 'handle_LOW'] = a2p_lower.ix[0,'HANDLE']\n",
    "    except:\n",
    "        unmatched.ix[unmatched.index == index, 'LOW'] = np.nan\n",
    "        unmatched.ix[unmatched.index == index, 'street_LOW'] = np.nan\n",
    "        unmatched.ix[unmatched.index == index, 'handle_LOW'] = np.nan            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in unmatched.iterrows():\n",
    "    try:\n",
    "        samestreet = a2p.STREETNAME==row['STREET_NAME']\n",
    "        sameblock = a2p.BLOCK==row['BLOCK']\n",
    "        evenOdd = a2p.EVEN==row['EVEN']\n",
    "        higher = a2p.HOUSENUM>=row['HOUSE']\n",
    "        a2p_higher = a2p[samestreet][sameblock][evenOdd][higher].reset_index() \n",
    "        unmatched.ix[unmatched.index == index, 'house_HIGH'] = a2p_higher.ix[0,'HOUSENUM']\n",
    "        unmatched.ix[unmatched.index == index, 'street_HIGH'] = a2p_higher.ix[0,'STREETNAME']\n",
    "        unmatched.ix[unmatched.index == index, 'handle_HIGH'] = a2p_higher.ix[0,'HANDLE']\n",
    "    except:\n",
    "        unmatched.ix[unmatched.index == index, 'HIGH'] = np.nan\n",
    "        unmatched.ix[unmatched.index == index, 'street_HIGH'] = np.nan\n",
    "        unmatched.ix[unmatched.index == index, 'handle_HIGH'] = np.nan    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = unmatched['STREET_NAME'].notnull()     \n",
    "unmatched['match_type'][mask] = 'between'\n",
    "\n",
    "unmatched['HANDLE_M1'][mask] = unmatched['handle_LOW']\n",
    "unmatched['HANDLE_M1'][mask & unmatched['handle_LOW'].isnull()] = unmatched['handle_HIGH']\n",
    "unmatched['HANDLE_M2'][mask & unmatched['handle_LOW'].notnull()] = unmatched['handle_HIGH']\n",
    "unmatched['HANDLE_M2'][unmatched['HANDLE_M1']==unmatched['HANDLE_M2']] = np.nan\n",
    "unmatched['HANDLE_M1'][mask & unmatched['HANDLE_M1'].isnull()] = 7777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The few remaining addresses were resolved by hand. 9999 is assigned if the address is outside city limits. 7777 is assigned if the address cannot be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign handles to the last stragglers by hand using visual inspection in ArcGIS \n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1'].str.contains(pat='DOMBARD LN')] = 9999\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1'].str.contains(pat='DOMBARD LN')] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='444 N VAN BUREN AVE'] = 9999\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='444 N VAN BUREN AVE'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='9807 LAWNVIEW DR'] = 9999\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='9807 LAWNVIEW DR'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='SALISBURY PARK HOMES - BUILDING LOT'] = 7777\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='SALISBURY PARK HOMES - BUILDING LOT'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='LOT 3 CABANNE AVE'] = 7777\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='LOT 3 CABANNE AVE'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='6334 BISHOP PLACE'] = 7777\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='6334 BISHOP PLACE'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='ONE MORGAN ST'] = 7777\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='ONE MORGAN ST'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='SALISBURY PARK HOMES - BUILDING LOT'] = 7777   \n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='SALISBURY PARK HOMES - BUILDING LOT'] = 'manual_straggler'   \n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='6502 W PARK AVE'] = 14893000100\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='6502 W PARK AVE'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='18 ARBERDEEN'] = 15639000020     \n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='18 ARBERDEEN'] = 'manual_straggler'     \n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='3625 FLAD HOUSE'] = 12118000120\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='3625 FLAD HOUSE'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='1212 REV G H PRUITT PL'] = 14553050450\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='1212 REV G H PRUITT PL'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='1927 SAINT LOUIS AVE'] = 11104000180\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='1927 SAINT LOUIS AVE'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M2'][unmatched['BEST_ADDR1']=='1927 SAINT LOUIS AVE'] = 11104000190\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='1927 SAINT LOUIS AVE'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M1'][unmatched['BEST_ADDR1']=='4140 DE TONTY ST'] = 15310000125\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='4140 DE TONTY ST'] = 'manual_straggler'\n",
    "\n",
    "unmatched['HANDLE_M2'][unmatched['BEST_ADDR1']=='4140 DE TONTY ST'] = 15310000135\n",
    "unmatched['match_type'][unmatched['BEST_ADDR1']=='4140 DE TONTY ST'] = 'manual_straggler'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent cells have focused on resolving the parcel for applications that didn't merge correctly at first. Add the handle assignments for these \"trouble\" applications back into the main lists of approved and denied applications. Also, combine approved and denied applications into one list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append the approved and denied lists, keeping track of reference numbers\n",
    "approved['refnum'] = approved['proj_num']\n",
    "matched = approved[['year', 'authorized', 'issued', 'owner', 'best_addr1', 'best_zip', 'HANDLE', 'refnum']]\n",
    "matched['result'] = 'approved'\n",
    "denied['result'] = denied['application']\n",
    "temp = denied[['year', 'result', 'best_addr1', 'best_zip', 'HANDLE', 'refnum']]\n",
    "matched = matched.append(temp, ignore_index=True)\n",
    "matched['best_addr1'] = matched['best_addr1'].astype(str)\n",
    "matched['best_zip'] = matched['best_zip'].astype(str)\n",
    "\n",
    "# Merge in handles for those that didn't match at first\n",
    "unmatched['best_addr1'] = unmatched['BEST_ADDR1'].astype(str)\n",
    "unmatched['best_zip'] = unmatched['BEST_ZIP'].astype(str)\n",
    "#unmatched['HANDLE_M1'] = unmatched['HANDLE']\n",
    "temp = unmatched[['best_addr1', 'best_zip', 'match_type', 'HANDLE_M1', 'HANDLE_M2', 'HANDLE_M3', 'HANDLE_M4']].drop_duplicates(['best_addr1', 'best_zip'])\n",
    "matched = matched.merge(temp, left_on=['best_addr1', 'best_zip'], right_on=['best_addr1', 'best_zip'], how='left')\n",
    "matched['HANDLE_M1'][matched['HANDLE'].notnull()] = matched['HANDLE']\n",
    "matched = matched.drop('HANDLE', axis=1)\n",
    "\n",
    "# Assign match type to applications that matched nicely at first\n",
    "mask = matched['match_type'].isnull()\n",
    "matched['match_type'][mask] = 'clean_match'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export the final list** of handle assignments for all applications to a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matched.to_csv('final_handle_assignments.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics of matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few **summary statistics**: \n",
    "1. Number of approved and denied applications, by type of match\n",
    "3. Number of applications assigned to multiple parcels\n",
    "4. Number of applications thrown out because they are outside city limits (\"9999\") or were not found (\"7777\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(matched['match_type'], matched['result'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matched[['HANDLE_M1', 'HANDLE_M2', 'HANDLE_M3', 'HANDLE_M4']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = matched[['result', 'HANDLE_M1', 'match_type']][matched['HANDLE_M1'].isin([7777, 9999])]\n",
    "pd.crosstab(summary['result'], summary['HANDLE_M1'], margins=True)\n",
    "# 9999 is outside city limits, 7777 are applications with addresses that couldn't be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(summary['match_type'], summary['HANDLE_M1'], margins=True)\n",
    "# 9999 is outside city limits, 7777 are applications with addresses that couldn't be found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrative maps of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map paths** from applicant addresses that didn't match initially to the parcels they were eventually matched with. This is a way to check results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First parcel match for each application (PARCEL_M1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pargeocd = pd.read_csv('pargeocd.csv', sep = \";\")\n",
    "pargeocd = pargeocd.drop_duplicates('HANDLE')\n",
    "trouble_map = unmatched.merge(pargeocd,left_on='HANDLE_M1', right_on='HANDLE', how='inner')\n",
    "trouble_map = trouble_map[['XCoord_x', 'YCoord_x', 'BEST_ADDRESS', 'match_type', 'HANDLE_M1', 'HANDLE_M2', 'HANDLE_M3', 'HANDLE_M4', 'XCoord_y', 'YCoord_y', 'HANDLE_y']]\n",
    "trouble_map['XCoord_x'][trouble_map['match_type']=='manual_multi'] = np.nan\n",
    "trouble_map['YCoord_x'][trouble_map['match_type']=='manual_multi'] = np.nan\n",
    "trouble_map['XCoord_x'][trouble_map['YCoord_x']==0] = np.nan\n",
    "trouble_map['YCoord_x'][trouble_map['YCoord_x']==0] = np.nan\n",
    "trouble_map.to_csv('trouble_map_M1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Set ArcPy environment settings\n",
    "arcpy.env.workspace = r'C:\\Users\\wyatt.clarke\\Documents\\ArcGIS\\Projects\\StLouis\\StLouis.gdb'\n",
    "arcpy.env.overwriteOutput = True\n",
    "    # Add points to ArcGIS as a Table and display them on the map\n",
    "        #TableToTable_conversion (in_rows, out_path, out_name, {where_clause}, {field_mapping}, {config_keyword})\n",
    "arcpy.TableToTable_conversion(r'C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\trouble_map_M1.csv', r'C:\\Users\\wyatt.clarke\\Documents\\ArcGIS\\Projects\\StLouis\\StLouis.gdb', \"trouble_M1\")\n",
    "        #MakeXYEventLayer_management(in_Table, x_coords, y_coords, out_Layer, spRef, z_coords)\n",
    "arcpy.management.MakeXYEventLayer(\"trouble_M1\", \"XCoord_x\", \"YCoord_x\", 'trouble_geocodes_layer_M1', \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\", None)\n",
    "arcpy.management.MakeXYEventLayer(\"trouble_M1\", \"XCoord_y\", \"YCoord_y\", 'trouble_parcels_layer_M1', \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\", None)\n",
    "        #CopyFeatures_management (in_features, out_feature_class, {config_keyword}, {spatial_grid_1}, {spatial_grid_2}, {spatial_grid_3})\n",
    "arcpy.management.CopyFeatures('trouble_geocodes_layer_M1', 'geocodes_M1', None, None, None, None)\n",
    "arcpy.management.CopyFeatures('trouble_parcels_layer_M1', 'parcels_M1', None, None, None, None)\n",
    "arcpy.management.CopyFeatures(r'C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\shapefiles\\prcl.shp', 'prcl', None, None, None, None)\n",
    "arcpy.management.CopyFeatures(r'C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\shapefiles\\stl_boundary.shp', 'stl_boundary', None, None, None, None)\n",
    "arcpy.management.CopyFeatures(r'C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\shapefiles\\pargeocd.shp', 'prcl_pts', None, None, None, None)\n",
    "    # Draw line between geocodes and parcels\n",
    "        #XYToLine_management (in_table, out_featureclass, startx_field, starty_field, endx_field, endy_field, {line_type}, {id_field}, {spatial_reference})\n",
    "arcpy.management.XYToLine(\"trouble_M1\", \"trouble_path_M1\", \"XCoord_x\", \"YCoord_x\", \"XCoord_y\", \"YCoord_y\", \"GEODESIC\", \"HANDLE_M1\", \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second parcel match (PARCEL_M2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pargeocd = pd.read_csv('pargeocd.csv', sep = \";\")\n",
    "pargeocd = pargeocd.drop_duplicates('HANDLE')\n",
    "trouble_map = unmatched.merge(pargeocd,left_on='HANDLE_M2', right_on='HANDLE', how='inner')\n",
    "trouble_map = trouble_map[['XCoord_x', 'YCoord_x', 'BEST_ADDRESS', 'match_type', 'HANDLE_M1', 'HANDLE_M2', 'HANDLE_M3', 'HANDLE_M4', 'XCoord_y', 'YCoord_y', 'HANDLE_y']]\n",
    "trouble_map['XCoord_x'][trouble_map['match_type']=='manual_multi'] = np.nan\n",
    "trouble_map['YCoord_x'][trouble_map['match_type']=='manual_multi'] = np.nan\n",
    "trouble_map['XCoord_x'][trouble_map['YCoord_x']==0] = np.nan\n",
    "trouble_map['YCoord_x'][trouble_map['YCoord_x']==0] = np.nan\n",
    "trouble_map.to_csv('trouble_map_M2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Set ArcPy environment settings\n",
    "arcpy.env.workspace = r'C:\\Users\\wyatt.clarke\\Documents\\ArcGIS\\Projects\\StLouis\\StLouis.gdb'\n",
    "arcpy.env.overwriteOutput = True\n",
    "    # Add points to ArcGIS as a Table and display them on the map\n",
    "        #TableToTable_conversion (in_rows, out_path, out_name, {where_clause}, {field_mapping}, {config_keyword})\n",
    "arcpy.TableToTable_conversion(r'C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\trouble_map_M2.csv', r'C:\\Users\\wyatt.clarke\\Documents\\ArcGIS\\Projects\\StLouis\\StLouis.gdb', \"trouble_M2\")\n",
    "        #MakeXYEventLayer_management(in_Table, x_coords, y_coords, out_Layer, spRef, z_coords)\n",
    "arcpy.management.MakeXYEventLayer(\"trouble_M2\", \"XCoord_x\", \"YCoord_x\", 'trouble_geocodes_layer_M2', \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\", None)\n",
    "arcpy.management.MakeXYEventLayer(\"trouble_M2\", \"XCoord_y\", \"YCoord_y\", 'trouble_parcels_layer_M2', \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\", None)\n",
    "        #CopyFeatures_management (in_features, out_feature_class, {config_keyword}, {spatial_grid_1}, {spatial_grid_2}, {spatial_grid_3})\n",
    "arcpy.management.CopyFeatures('trouble_geocodes_layer_M2', 'geocodes_M2', None, None, None, None)\n",
    "arcpy.management.CopyFeatures('trouble_parcels_layer_M2', 'parcels_M2', None, None, None, None)\n",
    "    # Draw line between geocodes and parcels\n",
    "        #XYToLine_management (in_table, out_featureclass, startx_field, starty_field, endx_field, endy_field, {line_type}, {id_field}, {spatial_reference})\n",
    "arcpy.management.XYToLine(\"trouble_M2\", \"trouble_path_M2\", \"XCoord_x\", \"YCoord_x\", \"XCoord_y\", \"YCoord_y\", \"GEODESIC\", \"HANDLE_M2\", \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding cells produce the following maps. The full maps can be browsed in a map viewing application.\n",
    "\n",
    "The first map shows the paths between geocodes of applicant addresses with no exact match that fall on the street center line and the parcels to which they have been matched (ie, match_type=='between'). This picture demonstrates that the algorithm succeeds in matching these applicants to nearby parcels, because the paths are short. The second map zooms in on a section and displays the parcels.\n",
    "\n",
    "Note that applicant addresses that couldn't be geocoded are excluded. (That includes all the match_type=='manual_multi'.)\n",
    "<img src=\"shapefiles/between_paths.PNG\">\n",
    "<img src=\"shapefiles/between_paths_inset2.PNG\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now show geocodes of applications that were thrown out for being (1) outside city limits or (2) unable to be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excluded_9999 = unmatched[['XCoord', 'YCoord', 'BEST_ADDRESS', 'match_type', 'HANDLE_M1']][unmatched['HANDLE_M1']==9999]\n",
    "excluded_7777 = unmatched[['XCoord', 'YCoord', 'BEST_ADDRESS', 'match_type', 'HANDLE_M1']][unmatched['HANDLE_M1']==7777]\n",
    "excluded_9999.to_csv('excluded_9999.csv')\n",
    "excluded_7777.to_csv('excluded_7777.csv')\n",
    "\n",
    "    # Set ArcPy environment settings\n",
    "arcpy.env.workspace = r'C:\\Users\\wyatt.clarke\\Documents\\ArcGIS\\Projects\\StLouis\\StLouis.gdb'\n",
    "arcpy.env.overwriteOutput = True\n",
    "        #MakeXYEventLayer_management(in_Table, x_coords, y_coords, out_Layer, spRef, z_coords)\n",
    "arcpy.management.MakeXYEventLayer(r\"C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\excluded_9999.csv\", \"XCoord\", \"YCoord\", \"excluded_9999_Layer\", \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\", None)\n",
    "arcpy.management.MakeXYEventLayer(r\"C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\excluded_7777.csv\", \"XCoord\", \"YCoord\", \"excluded_7777_Layer\", \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\", None)\n",
    "        #CopyFeatures_management (in_features, out_feature_class, {config_keyword}, {spatial_grid_1}, {spatial_grid_2}, {spatial_grid_3})\n",
    "arcpy.management.CopyFeatures('excluded_9999_Layer', 'excluded_9999_Feature', None, None, None, None)\n",
    "arcpy.management.CopyFeatures('excluded_7777_Layer', 'excluded_7777_Feature', None, None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blue dots are unable to be matched to a parcel and tan dots are outside city limits.\n",
    "<img src=\"shapefiles/excluded.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all the parcels to which applicant addresses were matched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pargeocd = pd.read_csv('pargeocd.csv', sep = \";\")\n",
    "pargeocd = pargeocd.drop_duplicates('HANDLE')\n",
    "final_map = matched.merge(pargeocd,left_on='HANDLE_M1', right_on='HANDLE', how='inner')\n",
    "final_map.to_csv('final_map.csv')\n",
    "\n",
    "    # Set ArcPy environment settings\n",
    "arcpy.env.workspace = r'C:\\Users\\wyatt.clarke\\Documents\\ArcGIS\\Projects\\StLouis\\StLouis.gdb'\n",
    "arcpy.env.overwriteOutput = True\n",
    "        #MakeXYEventLayer_management(in_Table, x_coords, y_coords, out_Layer, spRef, z_coords)\n",
    "arcpy.management.MakeXYEventLayer(r\"C:\\Users\\wyatt.clarke\\Documents\\Research\\StLouis\\StLouisAddressMatching_JupyterNotebook\\final_map.csv\", \"XCoord\", \"YCoord\", \"final_map_Layer\", \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\", None)\n",
    "        #CopyFeatures_management (in_features, out_feature_class, {config_keyword}, {spatial_grid_1}, {spatial_grid_2}, {spatial_grid_3})\n",
    "arcpy.management.CopyFeatures('final_map_Layer', 'final_map_Feature', None, None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gray dots are the parcels to which applicant addresses were matched. Blue dots are geocodes of parcels that could not be matched.\n",
    "<img src=\"shapefiles/final2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left is a heatmap of postal addresses in St. Louis. Right is a heatmap of the postal addresses matched to an application.\n",
    "<img src=\"shapefiles/allVSmatched_parcels_heatmaps2.PNG\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
